Couche :  -> GLiNER(
  (model): TokenModel(
    (token_rep_layer): Encoder(
      (bert_layer): Transformer(
        (model): DebertaV2Model(
          (embeddings): DebertaV2Embeddings(
            (word_embeddings): Embedding(128004, 1024, padding_idx=0)
            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
            (dropout): StableDropout()
          )
          (encoder): DebertaV2Encoder(
            (layer): ModuleList(
              (0-23): 24 x DebertaV2Layer(
                (attention): DebertaV2Attention(
                  (self): DisentangledSelfAttention(
                    (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
                    (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
                    (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
                    (pos_dropout): StableDropout()
                    (dropout): StableDropout()
                  )
                  (output): DebertaV2SelfOutput(
                    (dense): Linear(in_features=1024, out_features=1024, bias=True)
                    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
                    (dropout): StableDropout()
                  )
                )
                (intermediate): DebertaV2Intermediate(
                  (dense): Linear(in_features=1024, out_features=4096, bias=True)
                  (intermediate_act_fn): GELUActivation()
                )
                (output): DebertaV2Output(
                  (dense): Linear(in_features=4096, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
                  (dropout): StableDropout()
                )
              )
            )
            (rel_embeddings): Embedding(512, 1024)
            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
          )
        )
      )
      (projection): Linear(in_features=1024, out_features=512, bias=True)
    )
    (rnn): LstmSeq2SeqEncoder(
      (lstm): LSTM(512, 256, batch_first=True, bidirectional=True)
    )
    (scorer): Scorer(
      (proj_token): Linear(in_features=512, out_features=1024, bias=True)
      (proj_label): Linear(in_features=512, out_features=1024, bias=True)
      (out_mlp): Sequential(
        (0): Linear(in_features=1536, out_features=2048, bias=True)
        (1): Dropout(p=0.1, inplace=False)
        (2): ReLU()
        (3): Linear(in_features=2048, out_features=3, bias=True)
      )
    )
  )
)
Couche : model -> TokenModel(
  (token_rep_layer): Encoder(
    (bert_layer): Transformer(
      (model): DebertaV2Model(
        (embeddings): DebertaV2Embeddings(
          (word_embeddings): Embedding(128004, 1024, padding_idx=0)
          (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
          (dropout): StableDropout()
        )
        (encoder): DebertaV2Encoder(
          (layer): ModuleList(
            (0-23): 24 x DebertaV2Layer(
              (attention): DebertaV2Attention(
                (self): DisentangledSelfAttention(
                  (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (pos_dropout): StableDropout()
                  (dropout): StableDropout()
                )
                (output): DebertaV2SelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
                  (dropout): StableDropout()
                )
              )
              (intermediate): DebertaV2Intermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): DebertaV2Output(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
                (dropout): StableDropout()
              )
            )
          )
          (rel_embeddings): Embedding(512, 1024)
          (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
        )
      )
    )
    (projection): Linear(in_features=1024, out_features=512, bias=True)
  )
  (rnn): LstmSeq2SeqEncoder(
    (lstm): LSTM(512, 256, batch_first=True, bidirectional=True)
  )
  (scorer): Scorer(
    (proj_token): Linear(in_features=512, out_features=1024, bias=True)
    (proj_label): Linear(in_features=512, out_features=1024, bias=True)
    (out_mlp): Sequential(
      (0): Linear(in_features=1536, out_features=2048, bias=True)
      (1): Dropout(p=0.1, inplace=False)
      (2): ReLU()
      (3): Linear(in_features=2048, out_features=3, bias=True)
    )
  )
)
Couche : model.token_rep_layer -> Encoder(
  (bert_layer): Transformer(
    (model): DebertaV2Model(
      (embeddings): DebertaV2Embeddings(
        (word_embeddings): Embedding(128004, 1024, padding_idx=0)
        (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
        (dropout): StableDropout()
      )
      (encoder): DebertaV2Encoder(
        (layer): ModuleList(
          (0-23): 24 x DebertaV2Layer(
            (attention): DebertaV2Attention(
              (self): DisentangledSelfAttention(
                (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
                (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
                (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
                (pos_dropout): StableDropout()
                (dropout): StableDropout()
              )
              (output): DebertaV2SelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
                (dropout): StableDropout()
              )
            )
            (intermediate): DebertaV2Intermediate(
              (dense): Linear(in_features=1024, out_features=4096, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): DebertaV2Output(
              (dense): Linear(in_features=4096, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
              (dropout): StableDropout()
            )
          )
        )
        (rel_embeddings): Embedding(512, 1024)
        (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
      )
    )
  )
  (projection): Linear(in_features=1024, out_features=512, bias=True)
)
Couche : model.token_rep_layer.bert_layer -> Transformer(
  (model): DebertaV2Model(
    (embeddings): DebertaV2Embeddings(
      (word_embeddings): Embedding(128004, 1024, padding_idx=0)
      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
      (dropout): StableDropout()
    )
    (encoder): DebertaV2Encoder(
      (layer): ModuleList(
        (0-23): 24 x DebertaV2Layer(
          (attention): DebertaV2Attention(
            (self): DisentangledSelfAttention(
              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (pos_dropout): StableDropout()
              (dropout): StableDropout()
            )
            (output): DebertaV2SelfOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
              (dropout): StableDropout()
            )
          )
          (intermediate): DebertaV2Intermediate(
            (dense): Linear(in_features=1024, out_features=4096, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): DebertaV2Output(
            (dense): Linear(in_features=4096, out_features=1024, bias=True)
            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
            (dropout): StableDropout()
          )
        )
      )
      (rel_embeddings): Embedding(512, 1024)
      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    )
  )
)
Couche : model.token_rep_layer.bert_layer.model -> DebertaV2Model(
  (embeddings): DebertaV2Embeddings(
    (word_embeddings): Embedding(128004, 1024, padding_idx=0)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
  (encoder): DebertaV2Encoder(
    (layer): ModuleList(
      (0-23): 24 x DebertaV2Layer(
        (attention): DebertaV2Attention(
          (self): DisentangledSelfAttention(
            (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
            (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
            (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
            (pos_dropout): StableDropout()
            (dropout): StableDropout()
          )
          (output): DebertaV2SelfOutput(
            (dense): Linear(in_features=1024, out_features=1024, bias=True)
            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
            (dropout): StableDropout()
          )
        )
        (intermediate): DebertaV2Intermediate(
          (dense): Linear(in_features=1024, out_features=4096, bias=True)
          (intermediate_act_fn): GELUActivation()
        )
        (output): DebertaV2Output(
          (dense): Linear(in_features=4096, out_features=1024, bias=True)
          (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
          (dropout): StableDropout()
        )
      )
    )
    (rel_embeddings): Embedding(512, 1024)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  )
)
Couche : model.token_rep_layer.bert_layer.model.embeddings -> DebertaV2Embeddings(
  (word_embeddings): Embedding(128004, 1024, padding_idx=0)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.embeddings.word_embeddings -> Embedding(128004, 1024, padding_idx=0)
Couche : model.token_rep_layer.bert_layer.model.embeddings.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.embeddings.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder -> DebertaV2Encoder(
  (layer): ModuleList(
    (0-23): 24 x DebertaV2Layer(
      (attention): DebertaV2Attention(
        (self): DisentangledSelfAttention(
          (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (pos_dropout): StableDropout()
          (dropout): StableDropout()
        )
        (output): DebertaV2SelfOutput(
          (dense): Linear(in_features=1024, out_features=1024, bias=True)
          (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
          (dropout): StableDropout()
        )
      )
      (intermediate): DebertaV2Intermediate(
        (dense): Linear(in_features=1024, out_features=4096, bias=True)
        (intermediate_act_fn): GELUActivation()
      )
      (output): DebertaV2Output(
        (dense): Linear(in_features=4096, out_features=1024, bias=True)
        (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
        (dropout): StableDropout()
      )
    )
  )
  (rel_embeddings): Embedding(512, 1024)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer -> ModuleList(
  (0-23): 24 x DebertaV2Layer(
    (attention): DebertaV2Attention(
      (self): DisentangledSelfAttention(
        (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
        (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
        (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
        (pos_dropout): StableDropout()
        (dropout): StableDropout()
      )
      (output): DebertaV2SelfOutput(
        (dense): Linear(in_features=1024, out_features=1024, bias=True)
        (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
        (dropout): StableDropout()
      )
    )
    (intermediate): DebertaV2Intermediate(
      (dense): Linear(in_features=1024, out_features=4096, bias=True)
      (intermediate_act_fn): GELUActivation()
    )
    (output): DebertaV2Output(
      (dense): Linear(in_features=4096, out_features=1024, bias=True)
      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
      (dropout): StableDropout()
    )
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.0 -> DebertaV2Layer(
  (attention): DebertaV2Attention(
    (self): DisentangledSelfAttention(
      (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (pos_dropout): StableDropout()
      (dropout): StableDropout()
    )
    (output): DebertaV2SelfOutput(
      (dense): Linear(in_features=1024, out_features=1024, bias=True)
      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
      (dropout): StableDropout()
    )
  )
  (intermediate): DebertaV2Intermediate(
    (dense): Linear(in_features=1024, out_features=4096, bias=True)
    (intermediate_act_fn): GELUActivation()
  )
  (output): DebertaV2Output(
    (dense): Linear(in_features=4096, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.0.attention -> DebertaV2Attention(
  (self): DisentangledSelfAttention(
    (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (pos_dropout): StableDropout()
    (dropout): StableDropout()
  )
  (output): DebertaV2SelfOutput(
    (dense): Linear(in_features=1024, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.0.attention.self -> DisentangledSelfAttention(
  (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (pos_dropout): StableDropout()
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.0.attention.self.query_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.0.attention.self.key_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.0.attention.self.value_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.0.attention.self.pos_dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.0.attention.self.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.0.attention.output -> DebertaV2SelfOutput(
  (dense): Linear(in_features=1024, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.0.attention.output.dense -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.0.attention.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.0.attention.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.0.intermediate -> DebertaV2Intermediate(
  (dense): Linear(in_features=1024, out_features=4096, bias=True)
  (intermediate_act_fn): GELUActivation()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.0.intermediate.dense -> Linear(in_features=1024, out_features=4096, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.0.intermediate.intermediate_act_fn -> GELUActivation()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.0.output -> DebertaV2Output(
  (dense): Linear(in_features=4096, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.0.output.dense -> Linear(in_features=4096, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.0.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.0.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.1 -> DebertaV2Layer(
  (attention): DebertaV2Attention(
    (self): DisentangledSelfAttention(
      (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (pos_dropout): StableDropout()
      (dropout): StableDropout()
    )
    (output): DebertaV2SelfOutput(
      (dense): Linear(in_features=1024, out_features=1024, bias=True)
      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
      (dropout): StableDropout()
    )
  )
  (intermediate): DebertaV2Intermediate(
    (dense): Linear(in_features=1024, out_features=4096, bias=True)
    (intermediate_act_fn): GELUActivation()
  )
  (output): DebertaV2Output(
    (dense): Linear(in_features=4096, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.1.attention -> DebertaV2Attention(
  (self): DisentangledSelfAttention(
    (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (pos_dropout): StableDropout()
    (dropout): StableDropout()
  )
  (output): DebertaV2SelfOutput(
    (dense): Linear(in_features=1024, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.1.attention.self -> DisentangledSelfAttention(
  (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (pos_dropout): StableDropout()
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.1.attention.self.query_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.1.attention.self.key_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.1.attention.self.value_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.1.attention.self.pos_dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.1.attention.self.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.1.attention.output -> DebertaV2SelfOutput(
  (dense): Linear(in_features=1024, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.1.attention.output.dense -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.1.attention.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.1.attention.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.1.intermediate -> DebertaV2Intermediate(
  (dense): Linear(in_features=1024, out_features=4096, bias=True)
  (intermediate_act_fn): GELUActivation()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.1.intermediate.dense -> Linear(in_features=1024, out_features=4096, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.1.intermediate.intermediate_act_fn -> GELUActivation()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.1.output -> DebertaV2Output(
  (dense): Linear(in_features=4096, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.1.output.dense -> Linear(in_features=4096, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.1.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.1.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.2 -> DebertaV2Layer(
  (attention): DebertaV2Attention(
    (self): DisentangledSelfAttention(
      (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (pos_dropout): StableDropout()
      (dropout): StableDropout()
    )
    (output): DebertaV2SelfOutput(
      (dense): Linear(in_features=1024, out_features=1024, bias=True)
      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
      (dropout): StableDropout()
    )
  )
  (intermediate): DebertaV2Intermediate(
    (dense): Linear(in_features=1024, out_features=4096, bias=True)
    (intermediate_act_fn): GELUActivation()
  )
  (output): DebertaV2Output(
    (dense): Linear(in_features=4096, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.2.attention -> DebertaV2Attention(
  (self): DisentangledSelfAttention(
    (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (pos_dropout): StableDropout()
    (dropout): StableDropout()
  )
  (output): DebertaV2SelfOutput(
    (dense): Linear(in_features=1024, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.2.attention.self -> DisentangledSelfAttention(
  (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (pos_dropout): StableDropout()
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.2.attention.self.query_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.2.attention.self.key_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.2.attention.self.value_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.2.attention.self.pos_dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.2.attention.self.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.2.attention.output -> DebertaV2SelfOutput(
  (dense): Linear(in_features=1024, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.2.attention.output.dense -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.2.attention.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.2.attention.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.2.intermediate -> DebertaV2Intermediate(
  (dense): Linear(in_features=1024, out_features=4096, bias=True)
  (intermediate_act_fn): GELUActivation()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.2.intermediate.dense -> Linear(in_features=1024, out_features=4096, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.2.intermediate.intermediate_act_fn -> GELUActivation()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.2.output -> DebertaV2Output(
  (dense): Linear(in_features=4096, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.2.output.dense -> Linear(in_features=4096, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.2.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.2.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.3 -> DebertaV2Layer(
  (attention): DebertaV2Attention(
    (self): DisentangledSelfAttention(
      (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (pos_dropout): StableDropout()
      (dropout): StableDropout()
    )
    (output): DebertaV2SelfOutput(
      (dense): Linear(in_features=1024, out_features=1024, bias=True)
      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
      (dropout): StableDropout()
    )
  )
  (intermediate): DebertaV2Intermediate(
    (dense): Linear(in_features=1024, out_features=4096, bias=True)
    (intermediate_act_fn): GELUActivation()
  )
  (output): DebertaV2Output(
    (dense): Linear(in_features=4096, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.3.attention -> DebertaV2Attention(
  (self): DisentangledSelfAttention(
    (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (pos_dropout): StableDropout()
    (dropout): StableDropout()
  )
  (output): DebertaV2SelfOutput(
    (dense): Linear(in_features=1024, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.3.attention.self -> DisentangledSelfAttention(
  (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (pos_dropout): StableDropout()
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.3.attention.self.query_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.3.attention.self.key_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.3.attention.self.value_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.3.attention.self.pos_dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.3.attention.self.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.3.attention.output -> DebertaV2SelfOutput(
  (dense): Linear(in_features=1024, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.3.attention.output.dense -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.3.attention.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.3.attention.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.3.intermediate -> DebertaV2Intermediate(
  (dense): Linear(in_features=1024, out_features=4096, bias=True)
  (intermediate_act_fn): GELUActivation()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.3.intermediate.dense -> Linear(in_features=1024, out_features=4096, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.3.intermediate.intermediate_act_fn -> GELUActivation()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.3.output -> DebertaV2Output(
  (dense): Linear(in_features=4096, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.3.output.dense -> Linear(in_features=4096, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.3.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.3.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.4 -> DebertaV2Layer(
  (attention): DebertaV2Attention(
    (self): DisentangledSelfAttention(
      (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (pos_dropout): StableDropout()
      (dropout): StableDropout()
    )
    (output): DebertaV2SelfOutput(
      (dense): Linear(in_features=1024, out_features=1024, bias=True)
      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
      (dropout): StableDropout()
    )
  )
  (intermediate): DebertaV2Intermediate(
    (dense): Linear(in_features=1024, out_features=4096, bias=True)
    (intermediate_act_fn): GELUActivation()
  )
  (output): DebertaV2Output(
    (dense): Linear(in_features=4096, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.4.attention -> DebertaV2Attention(
  (self): DisentangledSelfAttention(
    (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (pos_dropout): StableDropout()
    (dropout): StableDropout()
  )
  (output): DebertaV2SelfOutput(
    (dense): Linear(in_features=1024, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.4.attention.self -> DisentangledSelfAttention(
  (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (pos_dropout): StableDropout()
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.4.attention.self.query_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.4.attention.self.key_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.4.attention.self.value_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.4.attention.self.pos_dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.4.attention.self.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.4.attention.output -> DebertaV2SelfOutput(
  (dense): Linear(in_features=1024, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.4.attention.output.dense -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.4.attention.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.4.attention.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.4.intermediate -> DebertaV2Intermediate(
  (dense): Linear(in_features=1024, out_features=4096, bias=True)
  (intermediate_act_fn): GELUActivation()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.4.intermediate.dense -> Linear(in_features=1024, out_features=4096, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.4.intermediate.intermediate_act_fn -> GELUActivation()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.4.output -> DebertaV2Output(
  (dense): Linear(in_features=4096, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.4.output.dense -> Linear(in_features=4096, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.4.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.4.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.5 -> DebertaV2Layer(
  (attention): DebertaV2Attention(
    (self): DisentangledSelfAttention(
      (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (pos_dropout): StableDropout()
      (dropout): StableDropout()
    )
    (output): DebertaV2SelfOutput(
      (dense): Linear(in_features=1024, out_features=1024, bias=True)
      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
      (dropout): StableDropout()
    )
  )
  (intermediate): DebertaV2Intermediate(
    (dense): Linear(in_features=1024, out_features=4096, bias=True)
    (intermediate_act_fn): GELUActivation()
  )
  (output): DebertaV2Output(
    (dense): Linear(in_features=4096, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.5.attention -> DebertaV2Attention(
  (self): DisentangledSelfAttention(
    (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (pos_dropout): StableDropout()
    (dropout): StableDropout()
  )
  (output): DebertaV2SelfOutput(
    (dense): Linear(in_features=1024, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.5.attention.self -> DisentangledSelfAttention(
  (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (pos_dropout): StableDropout()
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.5.attention.self.query_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.5.attention.self.key_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.5.attention.self.value_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.5.attention.self.pos_dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.5.attention.self.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.5.attention.output -> DebertaV2SelfOutput(
  (dense): Linear(in_features=1024, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.5.attention.output.dense -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.5.attention.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.5.attention.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.5.intermediate -> DebertaV2Intermediate(
  (dense): Linear(in_features=1024, out_features=4096, bias=True)
  (intermediate_act_fn): GELUActivation()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.5.intermediate.dense -> Linear(in_features=1024, out_features=4096, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.5.intermediate.intermediate_act_fn -> GELUActivation()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.5.output -> DebertaV2Output(
  (dense): Linear(in_features=4096, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.5.output.dense -> Linear(in_features=4096, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.5.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.5.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.6 -> DebertaV2Layer(
  (attention): DebertaV2Attention(
    (self): DisentangledSelfAttention(
      (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (pos_dropout): StableDropout()
      (dropout): StableDropout()
    )
    (output): DebertaV2SelfOutput(
      (dense): Linear(in_features=1024, out_features=1024, bias=True)
      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
      (dropout): StableDropout()
    )
  )
  (intermediate): DebertaV2Intermediate(
    (dense): Linear(in_features=1024, out_features=4096, bias=True)
    (intermediate_act_fn): GELUActivation()
  )
  (output): DebertaV2Output(
    (dense): Linear(in_features=4096, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.6.attention -> DebertaV2Attention(
  (self): DisentangledSelfAttention(
    (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (pos_dropout): StableDropout()
    (dropout): StableDropout()
  )
  (output): DebertaV2SelfOutput(
    (dense): Linear(in_features=1024, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.6.attention.self -> DisentangledSelfAttention(
  (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (pos_dropout): StableDropout()
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.6.attention.self.query_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.6.attention.self.key_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.6.attention.self.value_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.6.attention.self.pos_dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.6.attention.self.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.6.attention.output -> DebertaV2SelfOutput(
  (dense): Linear(in_features=1024, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.6.attention.output.dense -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.6.attention.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.6.attention.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.6.intermediate -> DebertaV2Intermediate(
  (dense): Linear(in_features=1024, out_features=4096, bias=True)
  (intermediate_act_fn): GELUActivation()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.6.intermediate.dense -> Linear(in_features=1024, out_features=4096, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.6.intermediate.intermediate_act_fn -> GELUActivation()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.6.output -> DebertaV2Output(
  (dense): Linear(in_features=4096, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.6.output.dense -> Linear(in_features=4096, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.6.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.6.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.7 -> DebertaV2Layer(
  (attention): DebertaV2Attention(
    (self): DisentangledSelfAttention(
      (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (pos_dropout): StableDropout()
      (dropout): StableDropout()
    )
    (output): DebertaV2SelfOutput(
      (dense): Linear(in_features=1024, out_features=1024, bias=True)
      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
      (dropout): StableDropout()
    )
  )
  (intermediate): DebertaV2Intermediate(
    (dense): Linear(in_features=1024, out_features=4096, bias=True)
    (intermediate_act_fn): GELUActivation()
  )
  (output): DebertaV2Output(
    (dense): Linear(in_features=4096, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.7.attention -> DebertaV2Attention(
  (self): DisentangledSelfAttention(
    (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (pos_dropout): StableDropout()
    (dropout): StableDropout()
  )
  (output): DebertaV2SelfOutput(
    (dense): Linear(in_features=1024, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.7.attention.self -> DisentangledSelfAttention(
  (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (pos_dropout): StableDropout()
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.7.attention.self.query_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.7.attention.self.key_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.7.attention.self.value_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.7.attention.self.pos_dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.7.attention.self.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.7.attention.output -> DebertaV2SelfOutput(
  (dense): Linear(in_features=1024, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.7.attention.output.dense -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.7.attention.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.7.attention.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.7.intermediate -> DebertaV2Intermediate(
  (dense): Linear(in_features=1024, out_features=4096, bias=True)
  (intermediate_act_fn): GELUActivation()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.7.intermediate.dense -> Linear(in_features=1024, out_features=4096, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.7.intermediate.intermediate_act_fn -> GELUActivation()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.7.output -> DebertaV2Output(
  (dense): Linear(in_features=4096, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.7.output.dense -> Linear(in_features=4096, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.7.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.7.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.8 -> DebertaV2Layer(
  (attention): DebertaV2Attention(
    (self): DisentangledSelfAttention(
      (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (pos_dropout): StableDropout()
      (dropout): StableDropout()
    )
    (output): DebertaV2SelfOutput(
      (dense): Linear(in_features=1024, out_features=1024, bias=True)
      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
      (dropout): StableDropout()
    )
  )
  (intermediate): DebertaV2Intermediate(
    (dense): Linear(in_features=1024, out_features=4096, bias=True)
    (intermediate_act_fn): GELUActivation()
  )
  (output): DebertaV2Output(
    (dense): Linear(in_features=4096, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.8.attention -> DebertaV2Attention(
  (self): DisentangledSelfAttention(
    (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (pos_dropout): StableDropout()
    (dropout): StableDropout()
  )
  (output): DebertaV2SelfOutput(
    (dense): Linear(in_features=1024, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.8.attention.self -> DisentangledSelfAttention(
  (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (pos_dropout): StableDropout()
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.8.attention.self.query_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.8.attention.self.key_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.8.attention.self.value_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.8.attention.self.pos_dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.8.attention.self.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.8.attention.output -> DebertaV2SelfOutput(
  (dense): Linear(in_features=1024, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.8.attention.output.dense -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.8.attention.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.8.attention.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.8.intermediate -> DebertaV2Intermediate(
  (dense): Linear(in_features=1024, out_features=4096, bias=True)
  (intermediate_act_fn): GELUActivation()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.8.intermediate.dense -> Linear(in_features=1024, out_features=4096, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.8.intermediate.intermediate_act_fn -> GELUActivation()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.8.output -> DebertaV2Output(
  (dense): Linear(in_features=4096, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.8.output.dense -> Linear(in_features=4096, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.8.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.8.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.9 -> DebertaV2Layer(
  (attention): DebertaV2Attention(
    (self): DisentangledSelfAttention(
      (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (pos_dropout): StableDropout()
      (dropout): StableDropout()
    )
    (output): DebertaV2SelfOutput(
      (dense): Linear(in_features=1024, out_features=1024, bias=True)
      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
      (dropout): StableDropout()
    )
  )
  (intermediate): DebertaV2Intermediate(
    (dense): Linear(in_features=1024, out_features=4096, bias=True)
    (intermediate_act_fn): GELUActivation()
  )
  (output): DebertaV2Output(
    (dense): Linear(in_features=4096, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.9.attention -> DebertaV2Attention(
  (self): DisentangledSelfAttention(
    (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (pos_dropout): StableDropout()
    (dropout): StableDropout()
  )
  (output): DebertaV2SelfOutput(
    (dense): Linear(in_features=1024, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.9.attention.self -> DisentangledSelfAttention(
  (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (pos_dropout): StableDropout()
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.9.attention.self.query_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.9.attention.self.key_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.9.attention.self.value_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.9.attention.self.pos_dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.9.attention.self.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.9.attention.output -> DebertaV2SelfOutput(
  (dense): Linear(in_features=1024, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.9.attention.output.dense -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.9.attention.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.9.attention.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.9.intermediate -> DebertaV2Intermediate(
  (dense): Linear(in_features=1024, out_features=4096, bias=True)
  (intermediate_act_fn): GELUActivation()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.9.intermediate.dense -> Linear(in_features=1024, out_features=4096, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.9.intermediate.intermediate_act_fn -> GELUActivation()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.9.output -> DebertaV2Output(
  (dense): Linear(in_features=4096, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.9.output.dense -> Linear(in_features=4096, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.9.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.9.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.10 -> DebertaV2Layer(
  (attention): DebertaV2Attention(
    (self): DisentangledSelfAttention(
      (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (pos_dropout): StableDropout()
      (dropout): StableDropout()
    )
    (output): DebertaV2SelfOutput(
      (dense): Linear(in_features=1024, out_features=1024, bias=True)
      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
      (dropout): StableDropout()
    )
  )
  (intermediate): DebertaV2Intermediate(
    (dense): Linear(in_features=1024, out_features=4096, bias=True)
    (intermediate_act_fn): GELUActivation()
  )
  (output): DebertaV2Output(
    (dense): Linear(in_features=4096, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.10.attention -> DebertaV2Attention(
  (self): DisentangledSelfAttention(
    (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (pos_dropout): StableDropout()
    (dropout): StableDropout()
  )
  (output): DebertaV2SelfOutput(
    (dense): Linear(in_features=1024, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.10.attention.self -> DisentangledSelfAttention(
  (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (pos_dropout): StableDropout()
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.10.attention.self.query_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.10.attention.self.key_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.10.attention.self.value_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.10.attention.self.pos_dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.10.attention.self.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.10.attention.output -> DebertaV2SelfOutput(
  (dense): Linear(in_features=1024, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.10.attention.output.dense -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.10.attention.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.10.attention.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.10.intermediate -> DebertaV2Intermediate(
  (dense): Linear(in_features=1024, out_features=4096, bias=True)
  (intermediate_act_fn): GELUActivation()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.10.intermediate.dense -> Linear(in_features=1024, out_features=4096, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.10.intermediate.intermediate_act_fn -> GELUActivation()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.10.output -> DebertaV2Output(
  (dense): Linear(in_features=4096, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.10.output.dense -> Linear(in_features=4096, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.10.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.10.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.11 -> DebertaV2Layer(
  (attention): DebertaV2Attention(
    (self): DisentangledSelfAttention(
      (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (pos_dropout): StableDropout()
      (dropout): StableDropout()
    )
    (output): DebertaV2SelfOutput(
      (dense): Linear(in_features=1024, out_features=1024, bias=True)
      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
      (dropout): StableDropout()
    )
  )
  (intermediate): DebertaV2Intermediate(
    (dense): Linear(in_features=1024, out_features=4096, bias=True)
    (intermediate_act_fn): GELUActivation()
  )
  (output): DebertaV2Output(
    (dense): Linear(in_features=4096, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.11.attention -> DebertaV2Attention(
  (self): DisentangledSelfAttention(
    (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (pos_dropout): StableDropout()
    (dropout): StableDropout()
  )
  (output): DebertaV2SelfOutput(
    (dense): Linear(in_features=1024, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.11.attention.self -> DisentangledSelfAttention(
  (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (pos_dropout): StableDropout()
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.11.attention.self.query_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.11.attention.self.key_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.11.attention.self.value_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.11.attention.self.pos_dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.11.attention.self.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.11.attention.output -> DebertaV2SelfOutput(
  (dense): Linear(in_features=1024, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.11.attention.output.dense -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.11.attention.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.11.attention.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.11.intermediate -> DebertaV2Intermediate(
  (dense): Linear(in_features=1024, out_features=4096, bias=True)
  (intermediate_act_fn): GELUActivation()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.11.intermediate.dense -> Linear(in_features=1024, out_features=4096, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.11.intermediate.intermediate_act_fn -> GELUActivation()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.11.output -> DebertaV2Output(
  (dense): Linear(in_features=4096, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.11.output.dense -> Linear(in_features=4096, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.11.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.11.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.12 -> DebertaV2Layer(
  (attention): DebertaV2Attention(
    (self): DisentangledSelfAttention(
      (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (pos_dropout): StableDropout()
      (dropout): StableDropout()
    )
    (output): DebertaV2SelfOutput(
      (dense): Linear(in_features=1024, out_features=1024, bias=True)
      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
      (dropout): StableDropout()
    )
  )
  (intermediate): DebertaV2Intermediate(
    (dense): Linear(in_features=1024, out_features=4096, bias=True)
    (intermediate_act_fn): GELUActivation()
  )
  (output): DebertaV2Output(
    (dense): Linear(in_features=4096, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.12.attention -> DebertaV2Attention(
  (self): DisentangledSelfAttention(
    (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (pos_dropout): StableDropout()
    (dropout): StableDropout()
  )
  (output): DebertaV2SelfOutput(
    (dense): Linear(in_features=1024, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.12.attention.self -> DisentangledSelfAttention(
  (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (pos_dropout): StableDropout()
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.12.attention.self.query_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.12.attention.self.key_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.12.attention.self.value_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.12.attention.self.pos_dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.12.attention.self.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.12.attention.output -> DebertaV2SelfOutput(
  (dense): Linear(in_features=1024, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.12.attention.output.dense -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.12.attention.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.12.attention.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.12.intermediate -> DebertaV2Intermediate(
  (dense): Linear(in_features=1024, out_features=4096, bias=True)
  (intermediate_act_fn): GELUActivation()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.12.intermediate.dense -> Linear(in_features=1024, out_features=4096, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.12.intermediate.intermediate_act_fn -> GELUActivation()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.12.output -> DebertaV2Output(
  (dense): Linear(in_features=4096, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.12.output.dense -> Linear(in_features=4096, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.12.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.12.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.13 -> DebertaV2Layer(
  (attention): DebertaV2Attention(
    (self): DisentangledSelfAttention(
      (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (pos_dropout): StableDropout()
      (dropout): StableDropout()
    )
    (output): DebertaV2SelfOutput(
      (dense): Linear(in_features=1024, out_features=1024, bias=True)
      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
      (dropout): StableDropout()
    )
  )
  (intermediate): DebertaV2Intermediate(
    (dense): Linear(in_features=1024, out_features=4096, bias=True)
    (intermediate_act_fn): GELUActivation()
  )
  (output): DebertaV2Output(
    (dense): Linear(in_features=4096, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.13.attention -> DebertaV2Attention(
  (self): DisentangledSelfAttention(
    (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (pos_dropout): StableDropout()
    (dropout): StableDropout()
  )
  (output): DebertaV2SelfOutput(
    (dense): Linear(in_features=1024, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.13.attention.self -> DisentangledSelfAttention(
  (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (pos_dropout): StableDropout()
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.13.attention.self.query_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.13.attention.self.key_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.13.attention.self.value_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.13.attention.self.pos_dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.13.attention.self.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.13.attention.output -> DebertaV2SelfOutput(
  (dense): Linear(in_features=1024, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.13.attention.output.dense -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.13.attention.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.13.attention.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.13.intermediate -> DebertaV2Intermediate(
  (dense): Linear(in_features=1024, out_features=4096, bias=True)
  (intermediate_act_fn): GELUActivation()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.13.intermediate.dense -> Linear(in_features=1024, out_features=4096, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.13.intermediate.intermediate_act_fn -> GELUActivation()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.13.output -> DebertaV2Output(
  (dense): Linear(in_features=4096, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.13.output.dense -> Linear(in_features=4096, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.13.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.13.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.14 -> DebertaV2Layer(
  (attention): DebertaV2Attention(
    (self): DisentangledSelfAttention(
      (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (pos_dropout): StableDropout()
      (dropout): StableDropout()
    )
    (output): DebertaV2SelfOutput(
      (dense): Linear(in_features=1024, out_features=1024, bias=True)
      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
      (dropout): StableDropout()
    )
  )
  (intermediate): DebertaV2Intermediate(
    (dense): Linear(in_features=1024, out_features=4096, bias=True)
    (intermediate_act_fn): GELUActivation()
  )
  (output): DebertaV2Output(
    (dense): Linear(in_features=4096, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.14.attention -> DebertaV2Attention(
  (self): DisentangledSelfAttention(
    (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (pos_dropout): StableDropout()
    (dropout): StableDropout()
  )
  (output): DebertaV2SelfOutput(
    (dense): Linear(in_features=1024, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.14.attention.self -> DisentangledSelfAttention(
  (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (pos_dropout): StableDropout()
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.14.attention.self.query_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.14.attention.self.key_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.14.attention.self.value_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.14.attention.self.pos_dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.14.attention.self.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.14.attention.output -> DebertaV2SelfOutput(
  (dense): Linear(in_features=1024, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.14.attention.output.dense -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.14.attention.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.14.attention.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.14.intermediate -> DebertaV2Intermediate(
  (dense): Linear(in_features=1024, out_features=4096, bias=True)
  (intermediate_act_fn): GELUActivation()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.14.intermediate.dense -> Linear(in_features=1024, out_features=4096, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.14.intermediate.intermediate_act_fn -> GELUActivation()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.14.output -> DebertaV2Output(
  (dense): Linear(in_features=4096, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.14.output.dense -> Linear(in_features=4096, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.14.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.14.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.15 -> DebertaV2Layer(
  (attention): DebertaV2Attention(
    (self): DisentangledSelfAttention(
      (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (pos_dropout): StableDropout()
      (dropout): StableDropout()
    )
    (output): DebertaV2SelfOutput(
      (dense): Linear(in_features=1024, out_features=1024, bias=True)
      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
      (dropout): StableDropout()
    )
  )
  (intermediate): DebertaV2Intermediate(
    (dense): Linear(in_features=1024, out_features=4096, bias=True)
    (intermediate_act_fn): GELUActivation()
  )
  (output): DebertaV2Output(
    (dense): Linear(in_features=4096, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.15.attention -> DebertaV2Attention(
  (self): DisentangledSelfAttention(
    (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (pos_dropout): StableDropout()
    (dropout): StableDropout()
  )
  (output): DebertaV2SelfOutput(
    (dense): Linear(in_features=1024, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.15.attention.self -> DisentangledSelfAttention(
  (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (pos_dropout): StableDropout()
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.15.attention.self.query_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.15.attention.self.key_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.15.attention.self.value_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.15.attention.self.pos_dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.15.attention.self.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.15.attention.output -> DebertaV2SelfOutput(
  (dense): Linear(in_features=1024, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.15.attention.output.dense -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.15.attention.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.15.attention.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.15.intermediate -> DebertaV2Intermediate(
  (dense): Linear(in_features=1024, out_features=4096, bias=True)
  (intermediate_act_fn): GELUActivation()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.15.intermediate.dense -> Linear(in_features=1024, out_features=4096, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.15.intermediate.intermediate_act_fn -> GELUActivation()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.15.output -> DebertaV2Output(
  (dense): Linear(in_features=4096, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.15.output.dense -> Linear(in_features=4096, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.15.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.15.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.16 -> DebertaV2Layer(
  (attention): DebertaV2Attention(
    (self): DisentangledSelfAttention(
      (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (pos_dropout): StableDropout()
      (dropout): StableDropout()
    )
    (output): DebertaV2SelfOutput(
      (dense): Linear(in_features=1024, out_features=1024, bias=True)
      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
      (dropout): StableDropout()
    )
  )
  (intermediate): DebertaV2Intermediate(
    (dense): Linear(in_features=1024, out_features=4096, bias=True)
    (intermediate_act_fn): GELUActivation()
  )
  (output): DebertaV2Output(
    (dense): Linear(in_features=4096, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.16.attention -> DebertaV2Attention(
  (self): DisentangledSelfAttention(
    (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (pos_dropout): StableDropout()
    (dropout): StableDropout()
  )
  (output): DebertaV2SelfOutput(
    (dense): Linear(in_features=1024, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.16.attention.self -> DisentangledSelfAttention(
  (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (pos_dropout): StableDropout()
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.16.attention.self.query_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.16.attention.self.key_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.16.attention.self.value_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.16.attention.self.pos_dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.16.attention.self.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.16.attention.output -> DebertaV2SelfOutput(
  (dense): Linear(in_features=1024, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.16.attention.output.dense -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.16.attention.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.16.attention.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.16.intermediate -> DebertaV2Intermediate(
  (dense): Linear(in_features=1024, out_features=4096, bias=True)
  (intermediate_act_fn): GELUActivation()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.16.intermediate.dense -> Linear(in_features=1024, out_features=4096, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.16.intermediate.intermediate_act_fn -> GELUActivation()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.16.output -> DebertaV2Output(
  (dense): Linear(in_features=4096, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.16.output.dense -> Linear(in_features=4096, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.16.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.16.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.17 -> DebertaV2Layer(
  (attention): DebertaV2Attention(
    (self): DisentangledSelfAttention(
      (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (pos_dropout): StableDropout()
      (dropout): StableDropout()
    )
    (output): DebertaV2SelfOutput(
      (dense): Linear(in_features=1024, out_features=1024, bias=True)
      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
      (dropout): StableDropout()
    )
  )
  (intermediate): DebertaV2Intermediate(
    (dense): Linear(in_features=1024, out_features=4096, bias=True)
    (intermediate_act_fn): GELUActivation()
  )
  (output): DebertaV2Output(
    (dense): Linear(in_features=4096, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.17.attention -> DebertaV2Attention(
  (self): DisentangledSelfAttention(
    (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (pos_dropout): StableDropout()
    (dropout): StableDropout()
  )
  (output): DebertaV2SelfOutput(
    (dense): Linear(in_features=1024, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.17.attention.self -> DisentangledSelfAttention(
  (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (pos_dropout): StableDropout()
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.17.attention.self.query_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.17.attention.self.key_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.17.attention.self.value_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.17.attention.self.pos_dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.17.attention.self.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.17.attention.output -> DebertaV2SelfOutput(
  (dense): Linear(in_features=1024, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.17.attention.output.dense -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.17.attention.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.17.attention.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.17.intermediate -> DebertaV2Intermediate(
  (dense): Linear(in_features=1024, out_features=4096, bias=True)
  (intermediate_act_fn): GELUActivation()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.17.intermediate.dense -> Linear(in_features=1024, out_features=4096, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.17.intermediate.intermediate_act_fn -> GELUActivation()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.17.output -> DebertaV2Output(
  (dense): Linear(in_features=4096, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.17.output.dense -> Linear(in_features=4096, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.17.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.17.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.18 -> DebertaV2Layer(
  (attention): DebertaV2Attention(
    (self): DisentangledSelfAttention(
      (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (pos_dropout): StableDropout()
      (dropout): StableDropout()
    )
    (output): DebertaV2SelfOutput(
      (dense): Linear(in_features=1024, out_features=1024, bias=True)
      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
      (dropout): StableDropout()
    )
  )
  (intermediate): DebertaV2Intermediate(
    (dense): Linear(in_features=1024, out_features=4096, bias=True)
    (intermediate_act_fn): GELUActivation()
  )
  (output): DebertaV2Output(
    (dense): Linear(in_features=4096, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.18.attention -> DebertaV2Attention(
  (self): DisentangledSelfAttention(
    (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (pos_dropout): StableDropout()
    (dropout): StableDropout()
  )
  (output): DebertaV2SelfOutput(
    (dense): Linear(in_features=1024, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.18.attention.self -> DisentangledSelfAttention(
  (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (pos_dropout): StableDropout()
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.18.attention.self.query_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.18.attention.self.key_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.18.attention.self.value_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.18.attention.self.pos_dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.18.attention.self.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.18.attention.output -> DebertaV2SelfOutput(
  (dense): Linear(in_features=1024, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.18.attention.output.dense -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.18.attention.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.18.attention.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.18.intermediate -> DebertaV2Intermediate(
  (dense): Linear(in_features=1024, out_features=4096, bias=True)
  (intermediate_act_fn): GELUActivation()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.18.intermediate.dense -> Linear(in_features=1024, out_features=4096, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.18.intermediate.intermediate_act_fn -> GELUActivation()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.18.output -> DebertaV2Output(
  (dense): Linear(in_features=4096, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.18.output.dense -> Linear(in_features=4096, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.18.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.18.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.19 -> DebertaV2Layer(
  (attention): DebertaV2Attention(
    (self): DisentangledSelfAttention(
      (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (pos_dropout): StableDropout()
      (dropout): StableDropout()
    )
    (output): DebertaV2SelfOutput(
      (dense): Linear(in_features=1024, out_features=1024, bias=True)
      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
      (dropout): StableDropout()
    )
  )
  (intermediate): DebertaV2Intermediate(
    (dense): Linear(in_features=1024, out_features=4096, bias=True)
    (intermediate_act_fn): GELUActivation()
  )
  (output): DebertaV2Output(
    (dense): Linear(in_features=4096, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.19.attention -> DebertaV2Attention(
  (self): DisentangledSelfAttention(
    (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (pos_dropout): StableDropout()
    (dropout): StableDropout()
  )
  (output): DebertaV2SelfOutput(
    (dense): Linear(in_features=1024, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.19.attention.self -> DisentangledSelfAttention(
  (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (pos_dropout): StableDropout()
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.19.attention.self.query_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.19.attention.self.key_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.19.attention.self.value_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.19.attention.self.pos_dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.19.attention.self.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.19.attention.output -> DebertaV2SelfOutput(
  (dense): Linear(in_features=1024, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.19.attention.output.dense -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.19.attention.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.19.attention.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.19.intermediate -> DebertaV2Intermediate(
  (dense): Linear(in_features=1024, out_features=4096, bias=True)
  (intermediate_act_fn): GELUActivation()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.19.intermediate.dense -> Linear(in_features=1024, out_features=4096, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.19.intermediate.intermediate_act_fn -> GELUActivation()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.19.output -> DebertaV2Output(
  (dense): Linear(in_features=4096, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.19.output.dense -> Linear(in_features=4096, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.19.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.19.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.20 -> DebertaV2Layer(
  (attention): DebertaV2Attention(
    (self): DisentangledSelfAttention(
      (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (pos_dropout): StableDropout()
      (dropout): StableDropout()
    )
    (output): DebertaV2SelfOutput(
      (dense): Linear(in_features=1024, out_features=1024, bias=True)
      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
      (dropout): StableDropout()
    )
  )
  (intermediate): DebertaV2Intermediate(
    (dense): Linear(in_features=1024, out_features=4096, bias=True)
    (intermediate_act_fn): GELUActivation()
  )
  (output): DebertaV2Output(
    (dense): Linear(in_features=4096, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.20.attention -> DebertaV2Attention(
  (self): DisentangledSelfAttention(
    (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (pos_dropout): StableDropout()
    (dropout): StableDropout()
  )
  (output): DebertaV2SelfOutput(
    (dense): Linear(in_features=1024, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.20.attention.self -> DisentangledSelfAttention(
  (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (pos_dropout): StableDropout()
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.20.attention.self.query_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.20.attention.self.key_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.20.attention.self.value_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.20.attention.self.pos_dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.20.attention.self.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.20.attention.output -> DebertaV2SelfOutput(
  (dense): Linear(in_features=1024, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.20.attention.output.dense -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.20.attention.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.20.attention.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.20.intermediate -> DebertaV2Intermediate(
  (dense): Linear(in_features=1024, out_features=4096, bias=True)
  (intermediate_act_fn): GELUActivation()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.20.intermediate.dense -> Linear(in_features=1024, out_features=4096, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.20.intermediate.intermediate_act_fn -> GELUActivation()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.20.output -> DebertaV2Output(
  (dense): Linear(in_features=4096, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.20.output.dense -> Linear(in_features=4096, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.20.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.20.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.21 -> DebertaV2Layer(
  (attention): DebertaV2Attention(
    (self): DisentangledSelfAttention(
      (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (pos_dropout): StableDropout()
      (dropout): StableDropout()
    )
    (output): DebertaV2SelfOutput(
      (dense): Linear(in_features=1024, out_features=1024, bias=True)
      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
      (dropout): StableDropout()
    )
  )
  (intermediate): DebertaV2Intermediate(
    (dense): Linear(in_features=1024, out_features=4096, bias=True)
    (intermediate_act_fn): GELUActivation()
  )
  (output): DebertaV2Output(
    (dense): Linear(in_features=4096, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.21.attention -> DebertaV2Attention(
  (self): DisentangledSelfAttention(
    (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (pos_dropout): StableDropout()
    (dropout): StableDropout()
  )
  (output): DebertaV2SelfOutput(
    (dense): Linear(in_features=1024, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.21.attention.self -> DisentangledSelfAttention(
  (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (pos_dropout): StableDropout()
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.21.attention.self.query_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.21.attention.self.key_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.21.attention.self.value_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.21.attention.self.pos_dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.21.attention.self.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.21.attention.output -> DebertaV2SelfOutput(
  (dense): Linear(in_features=1024, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.21.attention.output.dense -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.21.attention.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.21.attention.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.21.intermediate -> DebertaV2Intermediate(
  (dense): Linear(in_features=1024, out_features=4096, bias=True)
  (intermediate_act_fn): GELUActivation()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.21.intermediate.dense -> Linear(in_features=1024, out_features=4096, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.21.intermediate.intermediate_act_fn -> GELUActivation()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.21.output -> DebertaV2Output(
  (dense): Linear(in_features=4096, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.21.output.dense -> Linear(in_features=4096, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.21.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.21.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.22 -> DebertaV2Layer(
  (attention): DebertaV2Attention(
    (self): DisentangledSelfAttention(
      (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (pos_dropout): StableDropout()
      (dropout): StableDropout()
    )
    (output): DebertaV2SelfOutput(
      (dense): Linear(in_features=1024, out_features=1024, bias=True)
      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
      (dropout): StableDropout()
    )
  )
  (intermediate): DebertaV2Intermediate(
    (dense): Linear(in_features=1024, out_features=4096, bias=True)
    (intermediate_act_fn): GELUActivation()
  )
  (output): DebertaV2Output(
    (dense): Linear(in_features=4096, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.22.attention -> DebertaV2Attention(
  (self): DisentangledSelfAttention(
    (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (pos_dropout): StableDropout()
    (dropout): StableDropout()
  )
  (output): DebertaV2SelfOutput(
    (dense): Linear(in_features=1024, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.22.attention.self -> DisentangledSelfAttention(
  (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (pos_dropout): StableDropout()
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.22.attention.self.query_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.22.attention.self.key_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.22.attention.self.value_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.22.attention.self.pos_dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.22.attention.self.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.22.attention.output -> DebertaV2SelfOutput(
  (dense): Linear(in_features=1024, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.22.attention.output.dense -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.22.attention.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.22.attention.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.22.intermediate -> DebertaV2Intermediate(
  (dense): Linear(in_features=1024, out_features=4096, bias=True)
  (intermediate_act_fn): GELUActivation()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.22.intermediate.dense -> Linear(in_features=1024, out_features=4096, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.22.intermediate.intermediate_act_fn -> GELUActivation()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.22.output -> DebertaV2Output(
  (dense): Linear(in_features=4096, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.22.output.dense -> Linear(in_features=4096, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.22.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.22.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.23 -> DebertaV2Layer(
  (attention): DebertaV2Attention(
    (self): DisentangledSelfAttention(
      (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
      (pos_dropout): StableDropout()
      (dropout): StableDropout()
    )
    (output): DebertaV2SelfOutput(
      (dense): Linear(in_features=1024, out_features=1024, bias=True)
      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
      (dropout): StableDropout()
    )
  )
  (intermediate): DebertaV2Intermediate(
    (dense): Linear(in_features=1024, out_features=4096, bias=True)
    (intermediate_act_fn): GELUActivation()
  )
  (output): DebertaV2Output(
    (dense): Linear(in_features=4096, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.23.attention -> DebertaV2Attention(
  (self): DisentangledSelfAttention(
    (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (pos_dropout): StableDropout()
    (dropout): StableDropout()
  )
  (output): DebertaV2SelfOutput(
    (dense): Linear(in_features=1024, out_features=1024, bias=True)
    (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
    (dropout): StableDropout()
  )
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.23.attention.self -> DisentangledSelfAttention(
  (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
  (pos_dropout): StableDropout()
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.23.attention.self.query_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.23.attention.self.key_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.23.attention.self.value_proj -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.23.attention.self.pos_dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.23.attention.self.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.23.attention.output -> DebertaV2SelfOutput(
  (dense): Linear(in_features=1024, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.23.attention.output.dense -> Linear(in_features=1024, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.23.attention.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.23.attention.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.23.intermediate -> DebertaV2Intermediate(
  (dense): Linear(in_features=1024, out_features=4096, bias=True)
  (intermediate_act_fn): GELUActivation()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.23.intermediate.dense -> Linear(in_features=1024, out_features=4096, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.23.intermediate.intermediate_act_fn -> GELUActivation()
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.23.output -> DebertaV2Output(
  (dense): Linear(in_features=4096, out_features=1024, bias=True)
  (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
  (dropout): StableDropout()
)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.23.output.dense -> Linear(in_features=4096, out_features=1024, bias=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.23.output.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.bert_layer.model.encoder.layer.23.output.dropout -> StableDropout()
Couche : model.token_rep_layer.bert_layer.model.encoder.rel_embeddings -> Embedding(512, 1024)
Couche : model.token_rep_layer.bert_layer.model.encoder.LayerNorm -> LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
Couche : model.token_rep_layer.projection -> Linear(in_features=1024, out_features=512, bias=True)
Couche : model.rnn -> LstmSeq2SeqEncoder(
  (lstm): LSTM(512, 256, batch_first=True, bidirectional=True)
)
Couche : model.rnn.lstm -> LSTM(512, 256, batch_first=True, bidirectional=True)
Couche : model.scorer -> Scorer(
  (proj_token): Linear(in_features=512, out_features=1024, bias=True)
  (proj_label): Linear(in_features=512, out_features=1024, bias=True)
  (out_mlp): Sequential(
    (0): Linear(in_features=1536, out_features=2048, bias=True)
    (1): Dropout(p=0.1, inplace=False)
    (2): ReLU()
    (3): Linear(in_features=2048, out_features=3, bias=True)
  )
)
Couche : model.scorer.proj_token -> Linear(in_features=512, out_features=1024, bias=True)
Couche : model.scorer.proj_label -> Linear(in_features=512, out_features=1024, bias=True)
Couche : model.scorer.out_mlp -> Sequential(
  (0): Linear(in_features=1536, out_features=2048, bias=True)
  (1): Dropout(p=0.1, inplace=False)
  (2): ReLU()
  (3): Linear(in_features=2048, out_features=3, bias=True)
)
Couche : model.scorer.out_mlp.0 -> Linear(in_features=1536, out_features=2048, bias=True)
Couche : model.scorer.out_mlp.1 -> Dropout(p=0.1, inplace=False)
Couche : model.scorer.out_mlp.2 -> ReLU()
Couche : model.scorer.out_mlp.3 -> Linear(in_features=2048, out_features=3, bias=True)
